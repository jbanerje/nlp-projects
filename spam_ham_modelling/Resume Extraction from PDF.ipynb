{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfc77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65fe43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "from spacy_streamlit import visualize_ner, visualize_tokens, visualize_textcat\n",
    "\n",
    "import pandas as pd\n",
    "import PyPDF2 as pdf\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f728e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./sample_data/Jagannath_Banerjee_Lead_Data_Scientist.pdf', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e865d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_data_pre_processing(text):\n",
    "\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub('\\n+', '', text).strip()\n",
    "    text = re.sub(r'\\s+', ' ',   text) \n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Iterate over the tokens\n",
    "    tokenized_content = [token.text for token in doc]\n",
    "    tokenized_content_str = ' '.join(tokenized_content)\n",
    "    \n",
    "    return tokenized_content, tokenized_content_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d4580743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_content(file):\n",
    "    \n",
    "    ''' Function to extract pdf data '''\n",
    "    \n",
    "    pdf_reader = pdf.PdfFileReader(file)\n",
    "    page_count = pdf_reader.getNumPages()\n",
    "    \n",
    "    if pdf_reader.getIsEncrypted():\n",
    "        print('File is Encrypted, provide Password')\n",
    "    else:\n",
    "        page1      = pdf_reader.getPage(0)\n",
    "        text_blob  = page1.extractText()\n",
    "    \n",
    "    return text_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d65015c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JAGANNATH BANERJEE\\n \\nLead Data Scientist | Medline Industries\\n \\nHealthcare | Cards & Payments\\n \\n \\nSkill Highlights\\n \\n \\n\\n \\nProgramming\\n:\\n \\nPython (Scikit\\n-\\nlearn, Pandas, NumPy, Statslib, Matplotlib, Seaborn, Dask, Flask\\n, Streamlit\\n), \\nJupyter Notebook, SQL \\n \\n\\n \\nMachine \\nLearning\\n:\\n \\nRegression, Classification and Clustering models \\n \\n\\n \\nDemand \\nForecasting\\n:\\n \\nFacebook Prophet, \\nNeural Prophet, LSTM, \\nStatistical Models \\n \\n\\n \\nChatbot\\n:\\n \\nKore.ai, Microsoft Power Virtual Assistant \\n \\n\\n \\nCloud:\\n \\nMicrosoft \\nAzure,\\n \\nGoogle Cloud\\n \\n\\n \\nDatabase:\\n \\nIBM DB2, Teradata, Oracle, MS SQL Server, Azure SQL DB, HANA \\n \\n\\n \\nVersion \\nControl:\\n \\nAzure DevOps, GitHub, Bitbucket \\n \\n\\n \\nAPI:\\n \\nReal\\n-\\nTime and Near \\nReal Time \\n \\n\\n \\nData \\nPresentation:\\n \\nTableau & Microsoft Power Point (Advanced) \\n \\n\\n \\nOthers:\\n \\nExcel (Advanced for Data Analysis) \\n \\n\\n \\nOperating \\nSystem\\n:\\n \\nLinux, Windows\\n \\n \\nWork Experience\\n \\n \\nMedline Industries\\n \\n|\\n \\nLead\\n \\nData Scientist \\n \\n \\n \\n \\n \\n \\nMar\\n \\n201\\n9\\n \\nto P\\nresent\\n \\n \\n\\n \\nBuilt\\n \\ndemand forecasting\\n \\nsyst\\nem\\n \\nthat optimizes and \\npredicts \\nmonthly \\ndemand of \\n350K \\nmaterials\\n \\nhaving\\n \\nintermittent, erratic a\\nnd lump\\ny demand patterns\\n \\nusing 61 \\nstatistical\\n \\nmodel\\n \\nvariations\\n. \\nAble to reduce \\nforecasting error from 67% to 32% leading to \\nsaving of \\nover \\n$\\n5\\n \\nMillion\\n/Year\\n \\nin\\n \\nexcess inventory\\n.\\n \\n \\n\\n \\nDevelo\\nped\\n \\nwarehouse inventory audit application\\n, using \\nrandom fore\\nst model\\n, \\nthat smartly \\npick\\ns\\n \\nitem\\n \\nfor \\naudit\\n \\nacross 50 warehouses on a\\n \\ndaily basis \\nlead\\ning\\n \\nto estimated savings of \\n$ 4M\\n/Year \\nin\\n \\nlabor save\\n, \\ntheft \\nand misplacement\\n.\\n \\n \\n \\n\\n \\nImplemented h\\nelpdesk\\n \\nchatbot\\n \\nwith kore.ai to enable customer order placement and tracking which is \\nestimated to save \\nover $50,000\\n \\na year. \\n \\n \\n\\n \\nDeveloped \\nOptical Cha\\nracter Recognition\\n \\nappl\\nication \\nto \\nread cheques and invoice\\ns \\nfor \\nfinance\\n \\nteam \\nusing \\nGoogle \\nVision API\\n. This \\nwill\\n \\nreplace existing Ab\\nb\\ny OCR an\\nd save \\n$50K/Year in l\\nicensing cost\\n \\nand over \\n$100K in manhour val\\nidations.\\n \\n \\n\\n \\nImplemented\\n \\nExpected time of arrival (E\\nTA) \\napplication to predic\\nt wh\\nen a\\n \\nbackorder\\n \\ni\\ntem will arrive \\ninto\\n \\nwarehouse an\\nd be shipped \\nto the customer\\n \\nusing Gradient B\\noosting Machine Regressor\\n \\nand logical model\\n \\nin Azure Classic. This application is heart of online order system.\\n \\n \\n\\n \\nBu\\ni\\nlt \\nc\\nustomer \\nchurn \\nanalysis appl\\nicat\\nion\\n \\nto identify \\nacute ca\\nre and \\npost\\n-\\nacute\\n \\ncare \\ncustomer \\nhaving high \\nprobability of \\nle\\naving\\n, using \\nrandom fo\\nre\\nst classifier model \\nwith 85% accuracy\\n. \\n \\n \\n\\n \\nF\\nounded Data Science team\\n, built Machine Learning & Cloud Infrastructure and grew to 6\\n-\\nmember team. \\n \\n \\n \\nCell\\n \\n  \\n:\\n \\n(240)\\n-\\n217\\n-\\n1809\\n \\nEmail\\n \\n \\n \\n: \\nJagannath.banerjee@gmail.com\\n \\nWebsite\\n: \\nhttps://jagannathbanerjee.com/\\n \\nGitHub\\n \\n:\\n \\nhttps://github.com/jbanerje\\n \\n \\n'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = read_pdf_content(file)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "06de55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_content, tokenized_content_str = perform_data_pre_processing(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b689c855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jagannath banerjee lead data scientist | medline industries healthcare | cards & payments skill highlights programming : python ( scikit - learn , pandas , numpy , statslib , matplotlib , seaborn , dask , flask , streamlit ) , jupyter notebook , sql machine learning : regression , classification and clustering models demand forecasting : facebook prophet , neural prophet , lstm , statistical models chatbot : kore.ai , microsoft power virtual assistant cloud : microsoft azure , google cloud database : ibm db2 , teradata , oracle , ms sql server , azure sql db , hana version control : azure devops , github , bitbucket api : real - time and near real time data presentation : tableau & microsoft power point ( advanced ) others : excel ( advanced for data analysis ) operating system : linux , windows work experience medline industries | lead data scientist mar 2019 to present built demand forecasting system that optimizes and predicts monthly demand of 350k materials having intermittent , erratic and lumpy demand patterns using 61 statistical model variations . able to reduce forecasting error from 67 % to 32 % leading to saving of over $ 5 million / year in excess inventory . developed warehouse inventory audit application , using random forest model , that smartly picks item for audit across 50 warehouses on a daily basis leading to estimated savings of $ 4m / year in labor save , theft and misplacement . implemented helpdesk chatbot with kore.ai to enable customer order placement and tracking which is estimated to save over $ 50,000 a year . developed optical character recognition application to read cheques and invoices for finance team using google vision api . this will replace existing abby ocr and save $ 50k / year in licensing cost and over $ 100k in manhour validations . implemented expected time of arrival ( eta ) application to predict when a backorder item will arrive into warehouse and be shipped to the customer using gradient boosting machine regressor and logical model in azure classic . this application is heart of online order system . built customer churn analysis application to identify acute care and post - acute care customer having high probability of leaving , using random forest classifier model with 85 % accuracy . founded data science team , built machine learning & cloud infrastructure and grew to 6 - member team . cell : ( 240)-217 - 1809 email : jagannath.banerjee@gmail.com website : https://jagannathbanerjee.com/ github : https://github.com/jbanerje'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_content_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c787dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_required_fields(text):\n",
    "    \n",
    "    ''' Function to extract persoanl details '''\n",
    "    \n",
    "    emails         = re.findall(r\"[a-zA-Z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+\", text)\n",
    "    urls           = re.findall(r\"https://github.com[:/](.*)\", text)\n",
    "    phone          = re.findall(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]', text)\n",
    "#     github_pages   = re.findall(r\"github.com/w+\", text)\n",
    "#     websites       = re.findall('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+', text)\n",
    "    \n",
    "    return emails, urls, phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "051c16c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['jagannath.banerjee@gmail.com'], ['jbanerje'], ['240)-217 - 1809'])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_required_fields(tokenized_content_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f59721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
